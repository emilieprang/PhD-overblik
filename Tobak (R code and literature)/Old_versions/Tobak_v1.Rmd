---
title: "Tobacco shopping and lockdown"
date: \small 02 July 2021
geometry: margin=3cm
header-includes:
  - \newcommand*{\secref}[1]{Section~\ref{#1}}
  - \usepackage{xcolor,colortbl}
  - \definecolor{gray1}{gray}{0.9}

output:
  pdf_document:
    keep_tex: true
    fig_caption: yes
fontsize: 11pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overall goal: cigarette purchase and lockdown

It is well-established that smoking is a risk factor for cardiovascular disease (REF), and recent studies show that smoking worsens the COVID-19 disease course (REF). Some studies from Italy and UK find that smoking decreased during lockdown (REF). No such studies have been found in a Danish context, and furthermore, these existing studies are based on self-reported smoking habits. In this paper, we wish to investigate if lockdown affected tobacco purchases among some groups, based on a time series of credit-card transactions from various Danish supermarkets. 

The lockdown period (68 days from 11 March 2020 to 18 May 2020) will be compared to three other control periods of equal length:

- 11 March 2019 to 18 May 2019 (68 days)
- 02 Jan 2020 to 10 March 2020 (68 days)
- 19 May 2020 to 26 July 2020 (68 days)

for the following groups

- 1) Sex.
- 2) Age (<18, 18-29, 30-39, 40-49, 50-69, >69).
- 3) Geography (region)
- 4) Education.
- 5) Lifestyle disease (blood lowering/cholesterol lowering drugs at least 6 months before chosen start).
- 6) Work sector 

# Supermarket transaction data structure

We have a large amount of supermarket transaction data, where each transaction is uniquely defined by person and time, and contains at least one item. In this framework, one can think of a transaction as a receipt. We let $K$ denote the total number of transactions in the database. Letting $M$ be the total number of items in the database, we define the set of items to be 

\begin{equation}
\label{item_set}
\mathcal{I} = \{I_1, I_2,...,I_M\},
\end{equation}

where item $m$ is denoted $I_m$. Each item is associated with a positive item price and item quantity. This information is contained in the variables \textbf{item}, \textbf{itemprice} (in DKK) and \textbf{quantity} as seen in table \ref{trans_table} below. Here, the gray and white colors mark the different transactions, which are identified uniquely by a transaction id, \textbf{TID}. Thus, in below example in table \ref{trans_table}, we have a database consisting of $K=5$ transactions, and $M=9$ items:
$$
\mathcal{I} = \{I_1,...,I_9\} = \{bread, dip, dressings, fresh \  eggs, apples, milk, wine, beef, yoghurt\}
$$

Note that the total price of the transaction (\textbf{transactionprice}) is based on itemprice and quantity.

\begin{center}
\begin{table}[h]
\begin{tabular}{|l|l|l|l|r|r|r|} 
\hline
 TID & person & time & item & itemprice & quantity & transactionprice \\
\hline
\hline
\rowcolor{gray1} 1 & 1 & 17-03-2019 08:03:00 & bread & $11.95$ & $1$ & $76.95$\\
\rowcolor{gray1} 1 & 1 & 17-03-2019 08:03:00 & dip & $6.00$ & $2$ & $76.95$\\
\rowcolor{gray1} 1 & 1 & 17-03-2019 08:03:00 & dressings & $53.00$ & $1$ & $76.95$\\
2 & 1 & 19-03-2019 10:15:53 & fresh eggs & $27.95$ & $1$ & $78.40$\\
2 & 1 & 19-03-2019 10:15:53 & apples & $15.00$ & $0.700$ & $78.40$\\
2 & 1 & 19-03-2019 10:15:53 & dip & $10.00$ & $2$ & $78.40$\\
2 & 1 & 19-03-2019 10:15:53 & bread & $19.95$ & $1$ & $78.40$\\
\rowcolor{gray1} 3 & 2 & 02-02-2020 19:34:01 & milk & $9.95$ & $1$ & $9.95$\\
4 & 2 & 14-02-2020 15:55:04 & wine & $109.00$ & $3$ & $479.80$\\
4 & 2 & 14-02-2020 15:55:04 & beef & $49.95$ & $2$ & $479.80$\\
4 & 2 & 14-02-2020 15:55:04 & yoghurt & $18.95$ & $1$ & $479.80$\\
4 & 2 & 14-02-2020 15:55:04 & bread & $5.00$ & $5$ & $479.80$\\
4 & 2 & 14-02-2020 15:55:04 & milk & $8.95$ & $1$ & $479.80$\\
\rowcolor{gray1} 5 & 2 & 20-02-2020 20:24:10 & apples & 2.00 & 2 & $19.00$\\
\rowcolor{gray1} 5 & 2 & 20-02-2020 20:24:10 & bread & 15.00 & 1 & $19.00$\\
... & ... & ... & ... & ... & ... \\
\hline
\end{tabular}
\caption{Transaction data example with 5 transactions and 9 different items.}
\label{trans_table}
\end{table}
\end{center}

- The structure of the transaction data is quite complex: each individual has multiple observations of transactions over time, and the transactions are quite irregular, meaning that the frequency of transactions differs over the weeks, months and between individuals. 
- The number of items for each transaction will also vary between individuals and through time, as seen in above table. Furthermore, we will have new individuals entering the study and people dropping out, or even individuals dropping out and entering again, which creates missing time gaps. 
- To describe this complex data structure we will adapt the theory of marked point processes \cite{kar} \cite{last}. 

# Supermarket transaction data: a marked point process

- Let $T_k$ be the time for the $k^{th}$ supermarket grocery transaction. For each transaction time, $T_k$, one or more items are purchased.
- For each transaction time $T_k$, we have information about the items in the transaction, which is described by $(X_{1}(T_k),...,X_{M}(T_k))$. Specifically, $X_{m}(T_k)=(P_{m}(T_k), Q_{m}(T_k))$ denotes a vector that contain information about price and quantity for item $m$ at time $T_k$.
- Consider the first transaction, $k=1$, from the example in table \ref{trans_table}. We have three different items $I_1=bread$, $I_2=dip$ and $I_3=dressings$, with corresponding price and quantity. For bread we have:

$$
X_1(T_1) = (P_1(T_1), Q_1(T_1))=(11.95,1) \in \mathcal{X}_1 = \mathbb{R}^+ \times \mathbb{R}^+
$$

- Thus, for each transaction we have a positive real price and quantity for each item. We thus have a **mark space** for item $m$ given by $\mathcal{X}_m = \mathbb{R}^+ \times \mathbb{R}^+$.
- With this example in mind, we can now define the marked point process, $\phi$ for the transaction times, $T_k$.

\begin{equation}
\label{point}
\phi = (T_k, (X_1(T_k),...,X_M(T_k)))_{k\geq1}
\end{equation}

where each item has an associated mark space, such that $X_1(T_k) \in \mathcal{X}_1,...,X_M(T_k) \in \mathcal{X}_M$. Note that the mark spaces do not depend on transaction, but only on item, and the mark space for the entire set of items $\mathcal{I}$ is given by $\mathcal{X}_1 \times...\times \mathcal{X}_M$.

- Note that in most cases the quantities will be natural numbers, however, in some cases the quantity will be measured in kg or g, and the corresponding price will then be price per kg or price per g. As an example, see transaction two in table \ref{trans_table}, where the costumer bought 0.7 kg apples that cost 15.00 DKK per kg. 
- The defined marked point process from (\ref{point}) counts the number of transactions made up to and including time t. When considering the process as a function of $t$, we have an integer-valued step function with jumps of size $+1$, which we assume to be right-continous, so that $N(t)$ is the number of events in the time interval $[0,t]$:

\begin{equation}
\label{count}
N(t)=\sum_{k\geq 1} I \{T_{k} \leq t\},
\end{equation}

where we assume $N(0)=0$. See figure below for an illustration of the marked point process as a counting process \cite{pis}.

\begin{center}
\begin{figure}
\label{point_process}
\includegraphics[]{point_process}
\end{figure}
\end{center}

# Target parameter including examples

**General target parameter**

- We focus on a fixed time period $t \in [a,b]$ which is the same for every person and an item or itemset $m^*$. Note that $m^*$ can be a specific item (example $m^*=\text{cigarettes}$) or an itemset (example $m^*=\text{sugary drinks} = \{\text{soda with sugar, ice tea, alcohol free beer}\}$). 
- We now wish to define a target parameter in a general way, such that this can be used to investigate different questions. Following Appendix 4 (example A4.4 in Last and Brandt), we can write the target for $m^*$ in the time period $[a,b]$ as a Lebesgue-Steiltjes integral. Here, we integrate with respect to the counting process defined above, as this process marks the arrivals of the transactions. We define:

\begin{align*}
\mu^{m^*}(a, b) &= E(\int_a^b f(X(t)) dN(t))\\ 
&= \sum_{k: \ a \leq T_k \leq b} E(f(X(T_k))),
\end{align*}

where $f(X(t))$ is a function defining the nature of the target. See below two examples for an understanding of this parameter.

**Example 1**

- We wish to investigate **the expected number of transactions containing** $m^*$ **for** $t\in[a,b]$. Then we would define $f(X(t)) = I_{\{Q^{m^*}(t) > 0, \ P^{m^*}(t) > 0 \}}$. So, $f(X(t))$ denotes the transactions where $m^*$ was bought, ie. we have a positive quantity and price for $m^*$. From this, we could also calculate for example the expected number of daily or monthly transactions in the period. 

**Example 2**

- The idea is to estimate the **expected relative budget spent per transaction on** $m^*$ **for** $t\in[a,b]$.
- We use the same expression for $\mu^{m^*}(a,b)$, however, now defining $f(X(t)) = \frac{P^{m^*}(t) \cdot Q^{m^*}(t)}{\sum_{m=1}^M P^m(t) \cdot Q^m(t)}$. We would then need to calculate:

$$
\mu_{rel}^{m^*}(a,b)= \frac{\mu^{m^*}(a, b)}{\sum_{k=1}^K I_{\{a \leq T_k \leq b \}}},
$$

where the denominater is the number of transactions in the period $[a,b]$.

## Including covariates and grocery shopping history 
  
If we were to compare different groups or include grocery shopping history, we could condition on a filtration, $\mathcal{F}^-$, which  denotes a set of possibly time varying covariates known just before time $t$ as well as the grocery shopping history up until time $t$. Note that the shopping history is known at time $T_k$, but the time varying covariates can change at any time point, $s$. So, we have:

$$
\mathcal{F}_{t^-} = \sigma\{Z(s): s < t, T_k, X(T_k): T_k < t\}
$$
Using this, the upper example questions could be extended as follows:

- **Example 1 extension:** Based on a two year period (a=01 Jan 2019 to b=01 Jan 2021), does the expected monthly number of transactions containing cigarettes change during lockdown for different age groups? 
- **Example 2 extension**: Is the expected relative budget spent on sugary drinks from 01.01.2019 until 31.12.2019 different for diabetic and non-diabetic households?

# Observed data: time scale and censoring

## Choice of time scale
We choose to use calender time scale and not time since storebox start. By doing this, we will take seasonality into account and compare the same transaction times for different subjects. In this way, we can investigate our hypothesis about the impact of lockdown on cigarette shopping, as supposed to truncating the time scale by using time since storebox start, as people enter at different time points. 

## Censoring
In the observed data, we have different scenarios, which can lead to censored data. Examples are pictured in Figure \ref{missing}. Here, we have shown transactions for five fictive subjects with and without cigarettes in the period 1 Jan 2020 until 1 Jan 2021. 

\begin{center}
\begin{figure}
\includegraphics[]{MissingData.png}
\caption{Missing mechanisms}
\label{missing}
\end{figure}
\end{center}

Firstly, note that we have the case of truncation by death as marked by the orange arrow. In this case, the observations are not censored, as we know for sure that a transaction cannot happen from the grave! Secondly, in the periods with large gap times between transactions, we do not know whether the subject stopped using storebox, for example by changing to another supermarket (example subject 3), or if the subject realistically did not do frequent grocery shopping. For now we will not make any assumptions about these transaction gap times.
In the periods marked by a red arrow, we know that the subject did not have a possibility of making a transaction using the storebox app. Therefore, the observed data is not complete as these periods are censored. Due to this censoring, $N(t)$ will not be fully observable, but only an incomplete version, $\tilde{N}_i(t)$ will be available for the $i^{th}$ subject:

$$
\tilde{N}_i(t)=N_i(t)C_i(t),
$$

where the periods with censored data are delayed entry (caused by late entry into storebox or immigration), data load errors and emigration (assuming that the subject does not return to Denmark in the period $[a,b]$). So, we define the censoring process for the $i^{th}$ subject as follows:

$$
C_i(t)= \begin{cases}
0 \ \ \ \text{if} \ \ a \leq t \leq \min(T_{i1}, b) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (\text{delayed entry}) \\
0 \ \ \ \text{if} \ \ \ e1^{\text{start}} \leq t \leq \min(e1^{\text{slut}},b) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (\text{data load error}) \\
0 \ \ \ \text{if} \ \ \ e2_i^{\text{start}} \leq t \leq \min(e2_i^{\text{slut}},b) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (\text{emigration}) \\
1 \ \ \ \text{otherwise} \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (\text{transactions observed})
\end{cases},
$$

where $e1_{\text{start}}, e1_{\text{slut}}$ denote the start and end dates for a data load error (same for all subjects) and $e2_i^{\text{start}}, e2_i^{\text{slut}}$ denote start end dates for emigration for subject $i$. The censoring process is shown in Figure \ref{censoring} for subject 2 from Figure \ref{missing}.

\begin{center}
\begin{figure}
\includegraphics[]{Censoring}
\caption{Example of the censoring process $C_2(t)$ for subject 2.}
\label{censoring}
\end{figure}
\end{center}

Thus, denoting the total number of transactions for subject $i$ by $K_i$, we have the following observed data for subjects $i=1,...,n$ in the period $[a,b]$:

$$
(C_i(t), \tilde{N}_i(t): a \leq t \leq b, \max(T_{i1},a) \leq t \leq \min(T_{iK_i},b))_{i=1}^n
$$

Our job is now to estimate a chosen target parameter based on this observed data.

\newpage

## Estimation of the target parameter

First, we write up the target parameter for tobacco for the complete data, conditioning on information up to time $t$. Here, we use the tower property for conditional expectations.


\begin{align*}
\mu^{\text{tob}}(a, b) &= E(\int_a^b f(X(t)) dN(t))\\ 
&= E \left[ E(\int_a^b f(X(t)) dN(t) | \mathcal{F}_{t^-}) \right] \\
&= E \left[\int_a^b E(f(X(t)) dN(t) | \mathcal{F}_{t^-}) \right] \\
&= E \left[\int_a^b f(X(t)) E(dN(t) | \mathcal{F}_{t^-}) \right], 
\end{align*}


where $f(X(t)) = I_{\{Q^{\text{tob}}(t) > 0, \ P^{\text{tob}}(t) > 0 \}}$ indicates a tobacco transaction. We now with to estimate this target based on the intensity of buying tobacco. From \cite{gill84} we get the definition of an **intensity process**:

\begin{equation}
\label{intensity}
\lambda (t) dt =P(N \ \ \text{jumps in a time interval of length dt around time t} \ |  \mathcal{F}_{t^-})
\end{equation}

where $\mathcal{F}_{t^-}$ (defined earlier) denotes the past up to the beginning of the small time interval $dt$ (everything that has happened just before time $t$). In a small time interval, dt, $N$ either jumps once or does not jump at all. So the probability of a jump in that interval is close to the expected number of jumps in that interval \cite{gill84}. From the definition of the intensity, we therefore have:

$$
\lambda (t) dt = E(dN(t)| \mathcal{F}_{t^-})
$$

Inserting this in the target parameter, we get:

\begin{align*}
\mu^{\text{tob}}(a, b) &= E \left[\int_a^b f(X(t)) E(dN(t) | \mathcal{F}_{t^-}) \right] \\
&= E \left[\int_a^b f(X(t)) \lambda (t) dt \right]
\end{align*}

We now with to investigate this target parameter in and outside lockdown. Therefore, we define the following indicator for the lockdown period:

$$
L(t) = \begin{cases} 1, \ \  t\in [11.03.2020, 18.05.2020], \ \ T_k \in  [11.03.2020, 18.05.2020] \\
0, \ \ \text{otherwise}
\end{cases}
$$

We let $\overline{L}(t)$ be the complement of this indicator, thus indicating the non-lockdown period. So, we wish to investigate the null hypothesis:

$$
H_0: \mu^{\text{tob}}(a,b | L)=\mu^{\text{tob}}(a,b | \overline{L})
$$

that the expected number of tobacco transactions during and outside lockdown is the same.


To estimate this based on the observed data, we start by plugging in an estimator for the intensity, as defined in \cite{marubini} p. 77:

$$
\hat{\lambda}^{\text{tob}}=\frac{\text{total number of tobacco transactions}}{\text{total observation time (person-days)}}
$$

So, we get:

\begin{align*}
\hat{\mu}^{\text{tob}}(a, b) &= \int_a^b \hat{\lambda}^{\text{tob}} (t) dt
\end{align*}

as $f(X(t)) = I_{\{Q^{\text{tob}}(t) > 0, \ P^{\text{tob}}(t) > 0 \}}$ (indicates a tobacco transaction) is contained in the estimator for the intensity. Continuing this expression, for $i=1,...,n$ observed subjects we get:

\begin{align*}
\hat{\mu}^{\text{tob}}(a, b) &= \int_a^b \hat{\lambda}^{\text{tob}} (t) dt \\
&=\frac{\sum_{i=1}^n \tilde{N}_i^{\text{tob}}(t: a \leq t \leq b)}{\sum_{i=1}^n \sum_{j \ : \ a \leq t_j \leq b} C_i(t_j)}
\end{align*}

where $j=1,2,3,...$ such that $t_j$ represents calender day $j$ and $\tilde{N}_i^{\text{tob}}(t_j)$ is the observed number of tobacco transactions for subject i at time $t_j$. 

**During lockdown** for the fictive data, we get:

\begin{align*}
\hat{\mu}^{\text{tob}}(a, b | L) &= \int_a^b \hat{\lambda}^{\text{tob}} (t: a \leq t \leq b) L(t) dt \\
&=\frac{\sum_{i=1}^n \tilde{N}_i^{\text{tob}} (t: a \leq t \leq b) L(t)}{\sum_{i=1}^n \sum_{j \ : \ a \leq t_j \leq b} C_i(t_j) L(t_j)} \\
&=\frac{\sum_{i=1}^n \sum_{k \geq 1} I \{a \leq T^{tob}_{ik} \leq b\} L(T_k)}{\sum_{i=1}^n \sum_{j \ : \ a \leq t_j \leq b} C_i(t_j) L(t_j)} \\
&=\frac{1+2+0+5+1}{68+68+68+68+(68-13))} \\
&=\frac{9}{327} = 0.028 \ \ \text{tobacco trans / pers-day}
\end{align*}

This gives $0.028 \cdot 30.44 = 0.85$ tobacco transactions per person-month in the lockdown period.

**Outside lockdown** for the fictive data, we get (what about death?):

\begin{align*}
\hat{\mu}^{\text{tob}}(a, b | \overline{L}) &= \int_a^b \hat{\lambda}^{\text{tob}} (t: a \leq t \leq b) \overline{L}(t) dt \\
&=\frac{\sum_{i=1}^n \tilde{N}_i^{\text{tob}} (t: a \leq t \leq b) \overline{L}(t)}{\sum_{i=1}^n \sum_{j \ : \ a \leq t_j \leq b} C_i(t_j) \overline{L}(t_j)} \\
&=\frac{\sum_{i=1}^n \sum_{k \geq 1} I \{a \leq T^{tob}_{ik} \leq b\} \overline{L}(T_k)}{\sum_{i=1}^n \sum_{j \ : \ a \leq t_j \leq b} C_i(t_j) \overline{L}(t_j)} \\
&=\frac{7+3+7+3+3}{(297-30)+(297-30-30)+(297-40-30)+(297-72-30-60)+(297-72-30-75)} \\
&=\frac{23}{986}=0.023 \ \ \text{tob trans / pers-day}
\end{align*}

See Figure \ref{missing} to see the censored periods subtracted from the person-days in the denominator. 

This gives $0.023 \cdot 30.44 = 0.70$ tobacco transactions per person-month outside lockdown.

\newpage

## Additional notes: data dictionary and definition of kovariates

The following data dictionary gives the variables that we will include to model the expected number of soda transactions:

\begin{center}
\begin{table}[h]
\begin{tabular}{|l|l|l|l|} 
\hline
 Name & Label & Levels & Exp effect \\
\hline
hyp & Hypertension &  0 = No hypertension prior to storebox & Higher risk \\
 & for sb users &  1 = Hypertension prior to storebox &  \\
 & & defined by combination of two   & \\
 && medicines 180 days before start date & Lower risk \\
\hline
sex & Sex at sb start & Female & Lower risk \\
 & & Male & Higher risk \\
\hline
agegr & Age group at sb start & < 18 & Lower risk \\
 & & 18-29 & Higher risk \\
  & & 30-39 & Higher risk \\
   & & 40-49 & Higher risk \\
    & & 50-69 & Lower risk \\
     & & > 69 & Lower risk \\
     \hline
edu & Education at sb start & Basic & Higher risk \\
 & & Vocational training & Higher risk \\
  & & Upper secondary (videreg√•ende) & Lower risk \\
   & & Bachelor & Lower risk \\
    & & Higher education & Lower risk \\
    \hline
 householdn & Number in household & Continous & Higher risk \\
 & at sb start & & \\
     \hline
hotdogpast & Whether hotdogs was bought & 1 = hotdogs bought in [t-30,t] &  \\
& during the month & 0 otherwise& Lower risk\\
\hline
\end{tabular}
\caption{Data dictionary for variables to include in hotdog model}
\label{data_dic}
\end{table}
\end{center}

- Maybe define this way
- We have the following time invariant covariates:

$$
Z =\begin{bmatrix}
    Z^{\text{hypertension}}\\
    Z^{\text{sex}} \\
    Z^{\text{agegroup}} \\
    Z^{\text{education}} \\
    Z^{\text{number in household}}\\
\end{bmatrix},
$$
and one time dependent covariate, given by

$$
\bar{Z}^{\text{past}}(t) = 
\begin{cases}
 1 \ \text{if hotdogs were bought during the month [t-30 days, t] } \\ 
0 \ \text{otherwise}
\end{cases}
$$

 

\newpage 
\begin{thebibliography}{1}

\bibitem{gill82} Gill, D. R., Andersen, P. K. (1982). \textit{Understanding Cox's Regression Model: A Martingale Approach}, The Annals of Statistics, 10 (4), p. 1100-1120.

\bibitem{gill84} Gill, D. R. (1984). \textit{Understanding Cox's Regression Model: A Martingale Approach}, Journal of the American Statistical Association, 79 (386), p. 441-447.

\bibitem{statlearning} Hastie, T., Tibshirani, R., Friedman, J. (2009). \textit{The Elements of Statistical Learning} (Second ed.). Springer. 

\bibitem{kar} Karr, A. F. (1986). \textit{Point Processes and Their Statistical Inference} (First Ed.). Marcel Dekker.

\bibitem{last} Last, G., Brandt, A. (1995). \textit{Marked Point Processes on the Real Line} (First Ed.). Springer.

\bibitem{marubini} Marubini, E. (1995). \textit{Analysing Survival Data from Clinical Trials and Observational Studies} (First Ed.). John Wiley and Sons.

\bibitem{pis} Pishro-Nik, H. (2014). \textit{Introduction to Probability, Statistics, and Random Processes} (First ed.). Kappa Research. 

\bibitem{ch5} Tan, P. N., Steinbach, M., Karpatne, A., Kumar, V. (2019). \textit{Introduction to Data Mining} (First ed.). Pearson.

\bibitem{bay} Walley, Rosalind et al. (2016). \textit{Using Bayesian analysis in repeated preclinical in vivo studies for a more effective use of animals}, Pharmaceutical Statistics, No. 15, 2016, p. 277-285.

\end{thebibliography}
